# Voice Ledger - Complete Build Log

This document tracks every step taken to build the Voice Ledger prototype, with explanations of why each step is necessary and what outcome to expect.

---

## Project Setup

### Step 1: Verify Python Installation

**Command:**
```bash
python3 --version
```

**Why:** We need Python 3.10+ (or 3.9.6 minimum) to run all the components in the Voice Ledger system. This verifies the Python version available on the system.

**Expected Outcome:** Should display `Python 3.9.6` or higher.

**Actual Result:** `Python 3.9.6` âœ…

---

### Step 2: Create Virtual Environment

**Command:**
```bash
python3 -m venv venv
```

**Why:** A virtual environment isolates project dependencies from system-wide Python packages, preventing version conflicts and ensuring reproducible builds.

**Expected Outcome:** Creates a `venv/` directory with Python binaries and package management tools. No console output means success.

**Actual Result:** `venv/` folder created successfully âœ…

---

### Step 3: Activate Virtual Environment

**Command:**
```bash
source venv/bin/activate
```

**Why:** Activating the virtual environment ensures all subsequent `pip` installations and Python commands use the isolated environment rather than the system Python.

**Expected Outcome:** Terminal prompt changes to show `(venv)` prefix. Python commands now point to the virtual environment.

**Actual Result:** Virtual environment activated, `python --version` now works and shows `Python 3.9.6` âœ…

---

### Step 4: Create Project Directory Structure

**Command:**
```bash
mkdir -p voice/asr voice/nlu voice/service gs1 epcis ssi blockchain twin dpp docker tests dashboard examples
```

**Why:** The Technical Guide specifies a modular architecture where each lab has dedicated directories. Creating this structure upfront ensures organized development.

**Directory Purpose:**
- `voice/` - Lab 2: Audio processing, ASR, NLU
- `gs1/` - Lab 1: GS1 identifier generation
- `epcis/` - Lab 1: EPCIS 2.0 event construction
- `ssi/` - Lab 3: Self-sovereign identity and credentials
- `blockchain/` - Lab 4: Smart contracts and anchoring
- `twin/` - Lab 4: Digital twin synchronization
- `dpp/` - Lab 5: Digital Product Passports
- `docker/` - Lab 6: Containerization
- `tests/` - Lab 6: Automated testing
- `dashboard/` - Lab 6: Monitoring UI
- `examples/` - Sample data and demos

**Expected Outcome:** All directories created with no errors.

**Actual Result:** Full directory structure created successfully âœ…

---

### Step 5: Create Base Requirements File

**Command:**
```bash
# Created requirements.txt with:
pytest==7.4.3
```

**Why:** We start with minimal dependencies for Lab 1. Pytest is needed for testing our GS1 and EPCIS components. We'll add more packages as needed in subsequent labs.

**Expected Outcome:** `requirements.txt` file created with base testing framework.

**Actual Result:** File created âœ…

---

### Step 6: Install Base Python Packages

**Command:**
```bash
pip install -r requirements.txt
```

**Why:** Installs pytest and its dependencies into our virtual environment, enabling us to write and run tests for Lab 1 components.

**Expected Outcome:** Pytest 7.4.3 and dependencies installed. Warning about pip upgrade is non-critical.

**Actual Result:** Successfully installed:
- pytest==7.4.3
- packaging==25.0
- exceptiongroup==1.3.1
- iniconfig==2.1.0
- pluggy==1.6.0
- tomli==2.3.0
- typing-extensions==4.15.0

âœ… Project setup complete!

---

## Lab 1: GS1 Identifiers & EPCIS Events

### Step 1: Create GS1 Identifier Module

**File Created:** `gs1/identifiers.py`

**Why:** GS1 identifiers are the foundation of supply chain traceability. Before we can create EPCIS events, we need consistent ways to identify:
- **GLN (Global Location Number)** - Farms, warehouses, stations
- **GTIN (Global Trade Item Number)** - Coffee products/batches
- **SSCC (Serial Shipping Container Code)** - Logistic units (bags, pallets)

**What it does:**
- Uses a company prefix `0614141` (example prefix for this prototype)
- `gln(location_code)` - Generates 13-digit location identifiers
- `gtin(product_code)` - Generates 13-digit product identifiers
- `sscc(serial)` - Generates 18-digit logistic unit identifiers

**Test Command:**
```bash
python3 -c "
from gs1.identifiers import gln, gtin, sscc
print('GLN(10):', gln('10'))
print('GTIN(200):', gtin('200'))
print('SSCC(999):', sscc('999'))
"
```

**Expected Outcome:** Three valid GS1 identifiers printed to console.

**Actual Result:**
```
GLN(10): 0614141000010
GTIN(200): 0614141000200
SSCC(999): 00614141000000999
```
âœ… All identifiers generated correctly!

---

### Step 2: Create EPCIS Event Builder

**File Created:** `epcis/epcis_builder.py`

**Why:** EPCIS (Electronic Product Code Information Services) is the GS1 standard for capturing supply chain events. We need to create structured, standardized events that describe what happened, when, where, and to which items.

**What it does:**
- Creates EPCIS 2.0 JSON-LD ObjectEvents
- Generates "commissioning" events (batch creation/registration)
- Uses GS1 identifiers (SSCC, GLN, GTIN) from the previous step
- Saves events to `epcis/events/` directory as JSON files

**Event Structure:**
- `type`: "ObjectEvent" - describes an action on objects
- `action`: "ADD" - commissioning adds new items to the system
- `bizStep`: "commissioning" - the business process step
- `epcList`: List of items (using SSCC identifiers)
- `readPoint` / `bizLocation`: Where the event occurred (using GLN)
- `productClass`: What type of product (using GTIN)

**Test Command:**
```bash
python -m epcis.epcis_builder BATCH-2025-001
```

**Expected Outcome:** 
- Creates `epcis/events/BATCH-2025-001_commission.json`
- File contains valid EPCIS 2.0 JSON structure

**Actual Result:**
```
Created: epcis/events/BATCH-2025-001_commission.json
```

**Event Content Verified:**
```json
{
  "type": "ObjectEvent",
  "eventTime": "2025-01-01T00:00:00Z",
  "eventTimeZoneOffset": "+00:00",
  "epcList": ["urn:epc:id:sscc:00614141BATCH-2025-001"],
  "action": "ADD",
  "bizStep": "commissioning",
  "readPoint": {"id": "urn:epc:id:gln:0614141100001"},
  "bizLocation": {"id": "urn:epc:id:gln:0614141100001"},
  "productClass": "urn:epc:id:gtin:0614141200001",
  "batchId": "BATCH-2025-001"
}
```
âœ… EPCIS event created successfully!

---

### Step 3: Create Event Canonicalization Module

**File Created:** `epcis/canonicalise.py`

**Why:** JSON objects can have the same data but with fields in different orders. For example:
```json
{"name": "Alice", "age": 30}
{"age": 30, "name": "Alice"}
```
These are semantically identical but will produce different hashes. Canonicalization ensures deterministic hashing by:
1. Sorting all keys alphabetically
2. Removing all whitespace
3. Always producing the same string for the same data

This is **critical for blockchain anchoring** - we need the same event to always produce the same hash for verification.

**What it does:**
- Takes an EPCIS event JSON file path
- Loads and normalizes the JSON
- Returns a compact, sorted string representation

**Test Command:**
```bash
python3 -c "
from pathlib import Path
from epcis.canonicalise import canonicalise_event
canonical = canonicalise_event(Path('epcis/events/BATCH-2025-001_commission.json'))
print('Canonicalized:', canonical[:100] + '...')
print('Length:', len(canonical))
"
```

**Expected Outcome:** 
- Compact JSON string with sorted keys
- No whitespace or indentation
- Deterministic output

**Actual Result:**
```
Canonicalized: {"action":"ADD","batchId":"BATCH-2025-001","bizLocation":{"id":"urn:epc:id:gln:0614141100001"},...
Length: 358 characters
```
âœ… Canonicalization working correctly!

---

### Step 4: Create Event Hashing Module

**File Created:** `epcis/hash_event.py`

**Why:** Cryptographic hashes are the foundation of blockchain anchoring. A hash is a unique "fingerprint" of data that:
- Is deterministic (same input â†’ same hash)
- Is one-way (can't reverse engineer the original data)
- Changes completely if even one character changes
- Is fixed-length (always 64 hex characters for SHA-256)

These hashes will be stored on-chain as proof that an event existed, without revealing sensitive supply chain data publicly.

**What it does:**
- Takes a canonicalized EPCIS event
- Computes SHA-256 hash
- Returns 64-character hexadecimal string
- Can be run as CLI tool or imported as module

**Test Command:**
```bash
python -m epcis.hash_event epcis/events/BATCH-2025-001_commission.json
```

**Expected Outcome:** 
- 64-character hexadecimal hash
- Deterministic (same hash every time for same event)

**Actual Result (First run):**
```
Event hash: bc16581a015e8d239723f41734f0847b8615dcae996f182491ddffc67017b3fc
```

**Actual Result (Second run - verification):**
```
Event hash: bc16581a015e8d239723f41734f0847b8615dcae996f182491ddffc67017b3fc
```
âœ… Hash is deterministic - identical on both runs!

---

### Lab 1 Complete Pipeline Test

Let's verify the entire Lab 1 pipeline works end-to-end:

**Test Command:**
```bash
# Create a new batch event
python -m epcis.epcis_builder BATCH-TEST-001

# Hash the event
python -m epcis.hash_event epcis/events/BATCH-TEST-001_commission.json
```

**Expected Outcome:** New event created and hashed successfully.

**Actual Result:**
```
Created: epcis/events/BATCH-TEST-001_commission.json
Event hash: 16bafa768867d77e294f86d929f74e50b50399364d90603cc44f58041516bc58
```
âœ… Complete pipeline working perfectly!

---

## ðŸŽ‰ Lab 1 Complete Summary

**What we built:**
1. âœ… GS1 identifier generators (GLN, GTIN, SSCC)
2. âœ… EPCIS 2.0 event builder
3. âœ… Event canonicalization (deterministic JSON)
4. âœ… SHA-256 event hashing

**Pipeline flow:**
```
Batch ID â†’ GS1 Identifiers â†’ EPCIS Event â†’ Canonicalize â†’ Hash
```

**Deliverables:**
- `gs1/identifiers.py` - Identifier generation
- `epcis/epcis_builder.py` - Event creation
- `epcis/canonicalise.py` - Deterministic JSON normalization
- `epcis/hash_event.py` - Cryptographic hashing
- `epcis/events/` - Directory with event files

**Ready for:** Lab 2 (Voice & AI Layer)

---

### Step 5: Initialize Git Repository

**Commands:**
```bash
git init
git add .
git commit -m "Initial commit: Lab 1 complete - GS1 identifiers and EPCIS events"
```

**Why:** Version control is essential for:
- Tracking changes across all labs
- Reverting if something breaks
- Documenting progress with meaningful commits
- Eventually pushing to GitHub for backup/sharing

**What's in `.gitignore`:**
- Python artifacts (`__pycache__`, `*.pyc`, `venv/`)
- Generated files (EPCIS events, digital twins, DPP outputs)
- API keys and secrets (`.env` files)
- Blockchain build artifacts
- Audio test samples
- IDE configurations

**What's tracked:**
- All source code (`*.py`)
- Documentation (`*.md`)
- Configuration files (`requirements.txt`)
- Directory structure (`.gitkeep` files)

**Actual Result:**
```
[main (root-commit) 634feae] Initial commit: Lab 1 complete - GS1 identifiers and EPCIS events
13 files changed, 2306 insertions(+)
```

âœ… Git repository initialized and Lab 1 committed!

---

## Lab 2: Voice & AI Layer - Prerequisites

### API Keys and Setup Options

Before starting Lab 2, you need to decide on your ASR (Automatic Speech Recognition) and NLU (Natural Language Understanding) implementation approach.

#### Option A: OpenAI APIs (Recommended for beginners)

**What you need:**
- 1 OpenAI API key from: https://platform.openai.com/api-keys

**What it provides:**
- **Whisper API** for speech-to-text (ASR)
  - Cost: ~$0.006 per minute of audio
  - Highly accurate, supports 50+ languages
  - Simple API integration
  
- **GPT-3.5/GPT-4 API** for intent extraction (NLU)
  - Cost: ~$0.002 per request
  - Flexible entity and intent extraction
  - No training required

**Pros:**
- Fastest to implement
- Production-quality results immediately
- Single API key for both components

**Cons:**
- Requires internet connection
- Ongoing API costs (though minimal for testing)
- Data sent to OpenAI servers

---

#### Option B: Fully Local Implementation (No API keys needed)

**What you need:**
- No API keys
- Additional Python packages (we'll install together)
- More disk space (~1-3GB for models)

**What we'll use:**
- **Whisper (local)** - OpenAI's open-source model
  - Free, runs on your machine
  - Good quality (medium model recommended)
  - Slower than API but no costs
  
- **spaCy + Custom NLU** - Local intent classification
  - We'll train a simple model on supply chain intents
  - Fully offline
  - Complete control over the pipeline

**Pros:**
- Zero API costs
- Complete privacy (data stays local)
- Works offline
- Good learning experience

**Cons:**
- More setup time
- Requires decent CPU/RAM
- Model download time

---

#### Option C: Hybrid Approach

**Mix and match:**
- OpenAI Whisper API for ASR (paid)
- Local spaCy for NLU (free)

OR

- Local Whisper for ASR (free)
- OpenAI GPT for NLU (paid)

---

### Recommended Approach for This Build

**Start with stubs/mocks** (as shown in Technical Guide):
- Create the complete API structure
- Use simple mock functions that return hardcoded transcripts
- Test the full pipeline end-to-end
- Then integrate real ASR/NLU later

This allows us to:
1. Build and test the FastAPI service immediately
2. Verify the voice â†’ EPCIS event flow
3. Add real AI later without restructuring

**Decision needed before Lab 2:**
- [ ] Option A: OpenAI API key ready
- [ ] Option B: Build everything locally
- [ ] Option C: Hybrid approach
- [ ] Option D: Start with stubs, decide on real implementation later

---

### What We'll Build in Lab 2

Regardless of the API choice, Lab 2 will create:

1. **Audio preprocessing** (`voice/asr/preprocessing/audio_utils.py`)
   - Normalize volume
   - Reduce noise
   - Resample to 16kHz
   
2. **ASR module** (`voice/asr/asr_infer.py`)
   - Audio â†’ text transcription
   - Pluggable backend (stub, OpenAI, or local)
   
3. **NLU module** (`voice/nlu/nlu_infer.py`)
   - Text â†’ intent + entities
   - Extract: quantity, product, location, action
   
4. **FastAPI service** (`voice/service/api.py`)
   - `/asr-nlu` endpoint
   - File upload handling
   - API key authentication
   
5. **Authentication** (`voice/service/auth.py`)
   - API key middleware
   - Secure endpoint protection

---

## Lab 2: Voice & AI Layer - Implementation

**Implementation Choice:** OpenAI APIs (Whisper for ASR, GPT for NLU)

### Step 1: Install Lab 2 Dependencies

**Command:**
```bash
pip install -r requirements.txt
```

**Packages Added:**
- `fastapi==0.104.1` - Modern web framework for building APIs
- `uvicorn==0.24.0` - ASGI server to run FastAPI
- `python-multipart==0.0.6` - Required for file uploads
- `openai==1.3.5` - OpenAI API client
- `pydantic==2.5.0` - Data validation (FastAPI dependency)

**Why Each Package:**
- **FastAPI** - High-performance async framework, perfect for file uploads and AI integration
- **Uvicorn** - Production-ready ASGI server with great performance
- **python-multipart** - Handles multipart/form-data for audio file uploads
- **OpenAI** - Official client for Whisper (ASR) and GPT (NLU) APIs
- **Pydantic** - Type validation and serialization for API responses

**Expected Outcome:** All packages installed successfully.

**Actual Result:** Successfully installed fastapi, uvicorn, openai, and dependencies âœ…

---

### Step 2: Create API Authentication Module

**File Created:** `voice/service/auth.py`

**Why:** Secure API endpoints to ensure only authorized clients can submit voice commands. Uses API key authentication via HTTP headers.

**What it does:**
- Reads expected API key from `VOICE_LEDGER_API_KEY` environment variable
- Validates incoming `X-API-Key` header on protected endpoints
- Returns 401 Unauthorized if key is invalid
- Returns 500 if API key not configured

**Test:** Module imports successfully âœ…

---

### Step 3: Create ASR Module (Whisper Integration)

**File Created:** `voice/asr/asr_infer.py`

**Why:** Converts audio files to text transcriptions using OpenAI's Whisper API. This is the first stage of the voice pipeline.

**What it does:**
- Accepts audio file path (WAV, MP3, M4A formats supported)
- Sends audio to OpenAI Whisper API
- Returns clean text transcript
- Handles errors gracefully

**Dependencies Resolved:**
- Installed `openai==1.12.0` (compatible with Python 3.9)
- Installed `httpx==0.26.0` (compatible version)
- Installed `python-dotenv==1.0.0` for environment variable loading

**API Key:** Stored securely in `.env` file (git-ignored)

**Test:** Module loads successfully âœ…

---

### Step 4: Create NLU Module (Intent & Entity Extraction)

**File Created:** `voice/nlu/nlu_infer.py`

**Why:** Extracts structured information from transcripts. Identifies what action is being described (intent) and key details (entities) like quantity, product, locations.

**What it does:**
- Takes text transcript from ASR
- Uses GPT-3.5-turbo to extract:
  - **Intent**: `record_shipment`, `record_commission`, `record_receipt`, etc.
  - **Entities**: quantity, unit, product, origin, destination, batch_id
- Returns structured JSON
- Falls back gracefully if extraction fails

**Test Command:**
```bash
python -m voice.nlu.nlu_infer "Deliver 50 bags of washed coffee from station Abebe to Addis warehouse"
```

**Actual Result:**
```json
{
  "transcript": "Deliver 50 bags of washed coffee from station Abebe to Addis warehouse",
  "intent": "record_shipment",
  "entities": {
    "quantity": 50,
    "unit": "bags",
    "product": "washed coffee",
    "origin": "station Abebe",
    "destination": "Addis warehouse",
    "batch_id": null
  }
}
```
âœ… NLU extraction working perfectly!

---

### Step 5: Create FastAPI Service

**File Created:** `voice/service/api.py`

**Why:** Exposes the complete ASR â†’ NLU pipeline as a REST API that can be called by mobile apps, web UIs, or other services.

**What it provides:**
- `GET /` - Health check endpoint
- `POST /asr-nlu` - Main endpoint accepting audio files

**How it works:**
1. Accepts multipart/form-data file upload
2. Validates API key via `X-API-Key` header
3. Saves audio temporarily
4. Runs ASR (audio â†’ text)
5. Runs NLU (text â†’ intent + entities)
6. Returns structured JSON
7. Cleans up temp file

**Start Server:**
```bash
uvicorn voice.service.api:app --host 127.0.0.1 --port 8000
```

**Test Health Endpoint:**
```bash
curl http://localhost:8000/
```

**Actual Result:**
```json
{"service":"Voice Ledger ASR-NLU API","status":"operational","version":"1.0.0"}
```
âœ… API server running successfully!

---

### Step 6: Testing the Complete Voice Pipeline

**To test with a real audio file:**

1. Record or obtain an audio file (WAV, MP3, M4A)
2. Place it in `tests/samples/test_audio.wav`
3. Run:
```bash
curl -X POST "http://localhost:8000/asr-nlu" \
  -H "X-API-Key: dev-secret-key-2025" \
  -F "file=@tests/samples/test_audio.wav"
```

**Expected Response:**
```json
{
  "transcript": "[transcribed text]",
  "intent": "[detected intent]",
  "entities": {
    "quantity": number,
    "unit": "string",
    ...
  }
}
```

**Note:** For full testing, you'll need an actual audio file. The pipeline is ready and waiting for audio input.

---
