"""
Digital Product Passport Builder

Translates database batch data into EUDR-compliant DPP format.
Combines on-chain and off-chain data into consumer-facing passport.

v2.0 Enhancement: Multi-batch DPP generation for aggregated containers.
Implements Aggregation Implementation Roadmap Section 1.1.
"""

import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional, Dict, Any, List
from database import get_db, get_batch_by_batch_id, get_batch_events
from database.models import CoffeeBatch, AggregationRelationship, EPCISEvent, FarmerIdentity, VerificationPhoto
from sqlalchemy.orm import Session
from voice.verification.deforestation_checker import DeforestationChecker
import logging

logger = logging.getLogger(__name__)


def build_eudr_compliance_section(batch: CoffeeBatch, db: Session) -> Dict[str, Any]:
    """
    Build comprehensive EUDR compliance section with GPS photo verification.
    
    Implements EU Regulation 2023/1115 Article 9 requirements:
    - Geolocation coordinates of all production plots
    - Date of production
    - Traceability through supply chain
    - Risk assessment (deforestation-free)
    
    Args:
        batch: CoffeeBatch database object
        db: Database session
        
    Returns:
        EUDR compliance section dict
    """
    farmer = batch.farmer
    
    # Check GPS verification status
    has_registration_gps = farmer.photo_latitude is not None and farmer.photo_longitude is not None
    has_self_reported_gps = farmer.latitude is not None and farmer.longitude is not None
    
    # Get verification photos for this batch
    verification_photos = db.query(VerificationPhoto).filter_by(batch_id=batch.id).all()
    
    # Determine compliance status
    if has_registration_gps and farmer.gps_verified_at:
        if verification_photos:
            compliance_status = "FULLY_VERIFIED"  # Farm GPS + batch photos
            compliance_level = "Gold"
        else:
            compliance_status = "FARM_VERIFIED"  # Farm GPS only
            compliance_level = "Silver"
    elif has_self_reported_gps:
        compliance_status = "SELF_REPORTED"  # GPS but no photo proof
        compliance_level = "Bronze"
    else:
        compliance_status = "NO_GPS"  # Missing geolocation
        compliance_level = "Non-Compliant"
    
    eudr_section = {
        "regulation": {
            "name": "EU Deforestation Regulation (EUDR)",
            "reference": "Regulation (EU) 2023/1115",
            "article": "Article 9 - Geolocation Requirements",
            "applicableFrom": "2024-12-30"
        },
        "complianceStatus": compliance_status,
        "complianceLevel": compliance_level,
        "geolocation": {}
    }
    
    # Add farm registration geolocation (from photo EXIF)
    if has_registration_gps:
        eudr_section["geolocation"]["farmLocation"] = {
            "source": "GPS Photo Verification",
            "coordinates": {
                "latitude": farmer.photo_latitude,
                "longitude": farmer.photo_longitude
            },
            "verifiedAt": farmer.gps_verified_at.isoformat() if farmer.gps_verified_at else None,
            "photoTimestamp": farmer.photo_timestamp.isoformat() if farmer.photo_timestamp else None,
            "device": f"{farmer.photo_device_make or ''} {farmer.photo_device_model or ''}".strip() or "Unknown",
            "proof": {
                "photoHash": farmer.farm_photo_hash,
                "ipfsCID": farmer.farm_photo_ipfs,
                "blockchainTx": farmer.blockchain_proof_hash
            }
        }
    elif has_self_reported_gps:
        eudr_section["geolocation"]["farmLocation"] = {
            "source": "Self-Reported",
            "coordinates": {
                "latitude": farmer.latitude,
                "longitude": farmer.longitude
            },
            "warning": "Not cryptographically verified. Upload farm photo for full compliance."
        }
    else:
        eudr_section["geolocation"]["farmLocation"] = {
            "status": "MISSING",
            "warning": "Geolocation data required for EUDR compliance. Register with GPS photo."
        }
    
    # Add batch verification photos (harvest location proof)
    if verification_photos:
        eudr_section["geolocation"]["harvestVerification"] = []
        
        for photo in verification_photos:
            verification = {
                "verificationId": photo.id,
                "coordinates": {
                    "latitude": photo.latitude,
                    "longitude": photo.longitude
                },
                "timestamp": photo.photo_timestamp.isoformat() if photo.photo_timestamp else None,
                "verifiedAt": photo.verified_at.isoformat() if photo.verified_at else None,
                "device": f"{photo.device_make or ''} {photo.device_model or ''}".strip() or "Unknown",
                "distanceFromFarm": {
                    "value": photo.distance_from_farm_km,
                    "unit": "km",
                    "status": "VALID" if photo.distance_from_farm_km and photo.distance_from_farm_km < 50 else "WARNING"
                } if photo.distance_from_farm_km is not None else None,
                "proof": {
                    "photoHash": photo.photo_hash,
                    "ipfsCID": photo.photo_ipfs,
                    "blockchainTx": photo.blockchain_proof_hash
                }
            }
            eudr_section["geolocation"]["harvestVerification"].append(verification)
    
    # Add geographic boundaries (Ethiopia coffee-growing regions)
    if farmer.country_code == 'ET':
        eudr_section["geographicBoundary"] = {
            "country": "ET",
            "countryName": "Ethiopia",
            "region": farmer.region or batch.origin_region,
            "withinCoffeeBelt": True,
            "coordinates": {
                "bounds": {
                    "north": 15.0,
                    "south": 3.0,
                    "east": 48.0,
                    "west": 33.0
                }
            }
        }
    
    # Add risk assessment with actual deforestation check
    eudr_section["riskAssessment"] = {
        "deforestationRisk": "CHECKING",
        "riskFactors": [],
        "assessmentDate": datetime.now(timezone.utc).date().isoformat(),
        "assessor": "Voice Ledger GPS Verification System",
        "methodology": "Photo GPS EXIF extraction + Blockchain anchoring + Ethiopia boundary validation + Satellite imagery analysis"
    }
    
    # Perform actual deforestation check if we have GPS coordinates
    if has_registration_gps or has_self_reported_gps:
        try:
            checker = DeforestationChecker()
            lat = farmer.photo_latitude if has_registration_gps else farmer.latitude
            lon = farmer.photo_longitude if has_registration_gps else farmer.longitude
            
            deforestation_result = checker.check_deforestation(
                float(lat),
                float(lon),
                radius_meters=1000  # Check 1km radius around farm
            )
            
            # Store deforestation check results in database
            farmer.deforestation_checked_at = deforestation_result.check_date
            farmer.deforestation_risk = deforestation_result.risk_level
            farmer.deforestation_compliant = deforestation_result.compliant
            farmer.tree_cover_loss_hectares = deforestation_result.tree_cover_loss_hectares
            farmer.deforestation_data_source = deforestation_result.data_source
            farmer.deforestation_confidence = deforestation_result.confidence_score
            farmer.deforestation_details = deforestation_result.details
            db.commit()
            
            # Update risk assessment with actual results
            eudr_section["riskAssessment"]["deforestationRisk"] = deforestation_result.risk_level
            eudr_section["riskAssessment"]["deforestationCheck"] = {
                "detected": deforestation_result.deforestation_detected,
                "treeCoverLossHectares": deforestation_result.tree_cover_loss_hectares,
                "compliant": deforestation_result.compliant,
                "confidence": deforestation_result.confidence_score,
                "dataSource": deforestation_result.data_source,
                "methodology": deforestation_result.methodology,
                "checkedAt": deforestation_result.check_date.isoformat(),
                "eudrCutoffDate": "2020-12-31",
                "recommendation": deforestation_result.details.get("recommendation")
            }
            
            # Add appropriate risk factor based on deforestation status
            if not deforestation_result.compliant:
                eudr_section["riskAssessment"]["riskFactors"].append({
                    "factor": f"Deforestation detected: {deforestation_result.tree_cover_loss_hectares} hectares lost",
                    "severity": deforestation_result.risk_level,
                    "mitigation": deforestation_result.details.get("recommendation")
                })
            else:
                eudr_section["riskAssessment"]["riskFactors"].append({
                    "factor": "No deforestation detected after Dec 31, 2020",
                    "severity": "NONE",
                    "note": f"Satellite imagery confirms {deforestation_result.tree_cover_loss_hectares} hectares tree cover loss (below threshold)"
                })
                
            logger.info(f"Deforestation check completed for farmer {farmer.farmer_id}: {deforestation_result.risk_level} risk")
            
        except Exception as e:
            logger.error(f"Deforestation check failed for farmer {farmer.farmer_id}: {str(e)}")
            # Keep MEDIUM risk if check fails
            eudr_section["riskAssessment"]["deforestationRisk"] = "UNKNOWN"
            eudr_section["riskAssessment"]["deforestationCheck"] = {
                "status": "CHECK_FAILED",
                "error": str(e),
                "note": "Manual deforestation review required"
            }
            eudr_section["riskAssessment"]["riskFactors"].append({
                "factor": "Deforestation check unavailable",
                "severity": "MEDIUM",
                "mitigation": "Manual satellite imagery review required"
            })
    else:
        # No GPS coordinates available
        eudr_section["riskAssessment"]["deforestationRisk"] = "UNKNOWN"
        eudr_section["riskAssessment"]["deforestationCheck"] = {
            "status": "NO_GPS_COORDINATES",
            "note": "Cannot perform deforestation check without geolocation data"
        }
    
    # Add other risk factors based on compliance
    if compliance_status == "NO_GPS":
        eudr_section["riskAssessment"]["riskFactors"].append({
            "factor": "Missing geolocation data",
            "severity": "HIGH",
            "mitigation": "Upload farm photo with GPS for verification"
        })
    elif compliance_status == "SELF_REPORTED":
        eudr_section["riskAssessment"]["riskFactors"].append({
            "factor": "Geolocation not cryptographically verified",
            "severity": "MEDIUM",
            "mitigation": "Upload photo with EXIF GPS for cryptographic proof"
        })
    elif not verification_photos:
        eudr_section["riskAssessment"]["riskFactors"].append({
            "factor": "No harvest location verification photos",
            "severity": "LOW",
            "mitigation": "Upload photo from harvest location to strengthen compliance"
        })
    
    if not eudr_section["riskAssessment"]["riskFactors"]:
        eudr_section["riskAssessment"]["riskFactors"].append({
            "factor": "GPS verified with photo proof and no deforestation detected",
            "severity": "NONE",
            "note": "Full EUDR Article 9 and 10 compliance achieved"
        })
    
    # Add due diligence statement
    eudr_section["dueDiligenceStatement"] = {
        "operator": "Voice Ledger Supply Chain Platform",
        "statement": f"This batch has undergone GPS verification with compliance level: {compliance_level}. "
                    f"Geolocation data {'has been cryptographically verified via photo EXIF metadata' if has_registration_gps else 'is self-reported and requires photo verification'}.",
        "verificationMethod": "Photo GPS EXIF extraction + SHA-256 hashing + Blockchain anchoring",
        "dataRetention": "Immutable storage via IPFS + Ethereum blockchain",
        "nextReviewDate": (datetime.now(timezone.utc).date().replace(year=datetime.now(timezone.utc).year + 1)).isoformat()
    }
    
    return eudr_section


def load_batch_data(batch_id: str):
    """
    Load batch data from Neon database with eager-loaded relationships.
    
    Args:
        batch_id: Batch identifier (e.g., "BATCH-2025-001")
    
    Returns:
        CoffeeBatch object with relationships loaded, detached from session
    """
    with get_db() as db:
        batch = get_batch_by_batch_id(db, batch_id)
        if not batch:
            return None
        
        # Force load all relationships before expunging from session
        _  = batch.farmer.name  # Load farmer
        _ = batch.farmer.did
        _ = len(batch.farmer.credentials)  # Load credentials collection
        _ = [c.credential_type for c in batch.farmer.credentials]  # Load each credential
        _ = len(batch.events)  # Load events collection
        _ = [e.event_type for e in batch.events]  # Load each event
        
        # Expunge all related objects from session so they can be used outside
        db.expunge_all()
        
        return batch


def build_dpp(
    batch_id: str,
    product_name: Optional[str] = None,
    variety: Optional[str] = None,
    process_method: Optional[str] = None,
    country: Optional[str] = None,
    region: Optional[str] = None,
    cooperative: Optional[str] = None,
    deforestation_risk: str = "none",
    eudr_compliant: bool = True,
    resolver_base_url: str = "https://dpp.voiceledger.io"
) -> Dict[str, Any]:
    """
    Build a Digital Product Passport from database batch data.
    
    Args:
        batch_id: Batch identifier
        product_name: Product name (optional, defaults to batch data)
        variety: Coffee variety (optional, defaults to batch data)
        process_method: Processing method (optional, defaults to batch data)
        country: ISO 3166-1 alpha-2 country code (optional, defaults to batch data)
        region: Region/province (optional, defaults to batch data)
        cooperative: Cooperative name (optional, defaults to batch data)
        deforestation_risk: Risk level (none/low/medium/high)
        eudr_compliant: EUDR compliance status
        resolver_base_url: Base URL for DPP resolver
    
    Returns:
        Complete DPP dictionary
    """
    batch = load_batch_data(batch_id)
    
    if not batch:
        raise ValueError(f"Batch {batch_id} not found in database")
    
    # Generate passport ID
    passport_id = f"DPP-{batch_id}"
    issued_at = datetime.now(timezone.utc).isoformat()
    
    # Build product information from database
    product_info = {
        "productName": product_name or f"{batch.origin_region} {batch.variety} - {batch.process_method}",
        "quantity": batch.quantity_kg,
        "unit": "kg",
        "variety": variety or batch.variety,
        "processMethod": process_method or batch.process_method,
        "gtin": batch.gtin
    }
    
    # Build traceability section from database
    traceability = {
        "origin": {
            "country": country or batch.origin_country,
            "region": region or batch.origin_region,
            "farmName": batch.farm_name,
            "farmer": {
                "name": batch.farmer.name,
                "did": batch.farmer.did,
                "gln": batch.farmer.gln
            }
        },
        "supplyChainActors": [],
        "events": []
    }
    
    # Extract supply chain actors from farmer's credentials
    for cred in batch.farmer.credentials:
        if not cred.revoked:
            actor = {
                "role": cred.credential_type.replace("Certification", "").lower(),
                "name": batch.farmer.name,
                "did": cred.subject_did,
                "credential": {
                    "id": cred.credential_id,
                    "type": cred.credential_type,
                    "issuer": cred.issuer_did,
                    "issuedDate": cred.issuance_date.isoformat()
                }
            }
            traceability["supplyChainActors"].append(actor)
    
    # Extract EPCIS events from database
    for db_event in batch.events:
        event = {
            "eventType": db_event.event_type,
            "timestamp": db_event.event_time.isoformat() if db_event.event_time else issued_at,
            "eventHash": db_event.event_hash,
            "bizStep": db_event.biz_step,
            "blockchainAnchor": {
                "transactionHash": db_event.blockchain_tx_hash or "pending",
                "anchoredAt": db_event.blockchain_confirmed_at.isoformat() if db_event.blockchain_confirmed_at else None
            }
        }
        traceability["events"].append(event)
    
    # Build sustainability section from credentials
    sustainability = {
        "certifications": []
    }
    
    # Add certifications from farmer's credentials
    for cred in batch.farmer.credentials:
        if not cred.revoked and "certification" in cred.credential_type.lower():
            cert = {
                "type": cred.credential_type,
                "issuer": cred.issuer_did,
                "issuedDate": cred.issuance_date.isoformat(),
                "expiryDate": cred.expiration_date.isoformat() if cred.expiration_date else None
            }
            sustainability["certifications"].append(cert)
    
    # Placeholder for carbon footprint (would come from batch metadata)
    sustainability["carbonFootprint"] = {
        "value": 0.85,
        "unit": "kg CO2e/kg",
        "scope": "cradle-to-gate"
    }
    
    # Build due diligence section
    due_diligence = {
        "eudrCompliant": eudr_compliant,
        "riskAssessment": {
            "deforestationRisk": deforestation_risk,
            "assessmentDate": datetime.now(timezone.utc).date().isoformat(),
            "assessor": "Voice Ledger Platform",
            "methodology": "Satellite imagery + blockchain traceability"
        }
    }
    
    # Add due diligence credential reference if available
    dd_creds = [c for c in batch.farmer.credentials if "duediligence" in c.credential_type.lower()]
    if dd_creds:
        due_diligence["dueDiligenceStatement"] = dd_creds[0].credential_id
    
    # Build blockchain section from database events
    blockchain = {
        "network": "local",  # Would be "ethereum", "polygon", etc. in production
        "eventAnchorContract": "0x0000000000000000000000000000000000000000",  # Placeholder
        "anchors": []
    }
    
    # Add token information if available
    if batch.token_id:
        blockchain["tokenContract"] = "0x0000000000000000000000000000000000000000"
        blockchain["tokenId"] = batch.token_id
    
    # Format anchors from database events
    for event in batch.events:
        blockchain_anchor = {
            "eventHash": event.event_hash
        }
        
        if event.blockchain_tx_hash:
            blockchain_anchor["transactionHash"] = event.blockchain_tx_hash
            blockchain_anchor["anchoredAt"] = event.created_at.isoformat() if event.created_at else None
        
        blockchain["anchors"].append(blockchain_anchor)
    
    # Build QR code section
    dpp_url = f"{resolver_base_url}/dpp/{batch_id}"
    qr_code = {
        "url": dpp_url
    }
    
    # Build comprehensive EUDR compliance section with GPS photo verification
    with get_db() as db:
        fresh_batch = get_batch_by_batch_id(db, batch_id)
        eudr_compliance = build_eudr_compliance_section(fresh_batch, db)
    
    # Assemble complete DPP
    dpp = {
        "passportId": passport_id,
        "batchId": batch_id,
        "version": "2.0.0",  # Updated to 2.0 with EUDR GPS verification
        "issuedAt": issued_at,
        "productInformation": product_info,
        "traceability": traceability,
        "sustainability": sustainability,
        "dueDiligence": due_diligence,
        "eudrCompliance": eudr_compliance,  # NEW: Comprehensive EUDR section
        "blockchain": blockchain,
        "qrCode": qr_code
    }
    
    return dpp


def save_dpp(dpp: Dict[str, Any], output_dir: Optional[Path] = None) -> Path:
    """
    Save DPP to JSON file.
    
    Args:
        dpp: DPP dictionary
        output_dir: Output directory (defaults to dpp/passports/)
    
    Returns:
        Path to saved DPP file
    """
    if output_dir is None:
        output_dir = Path(__file__).parent / "passports"
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    batch_id = dpp["batchId"]
    output_file = output_dir / f"{batch_id}_dpp.json"
    
    with open(output_file, "w") as f:
        json.dump(dpp, f, indent=2, ensure_ascii=False)
    
    return output_file


def validate_dpp(dpp: Dict[str, Any]) -> tuple[bool, List[str]]:
    """
    Validate DPP against required fields.
    
    Args:
        dpp: DPP dictionary
    
    Returns:
        Tuple of (is_valid, list of errors)
    """
    errors = []
    
    # Check required top-level fields
    required_fields = [
        "passportId", "batchId", "version", "productInformation",
        "traceability", "dueDiligence", "blockchain"
    ]
    
    for field in required_fields:
        if field not in dpp:
            errors.append(f"Missing required field: {field}")
    
    # Check EUDR compliance fields
    if "dueDiligence" in dpp:
        dd = dpp["dueDiligence"]
        if "eudrCompliant" not in dd:
            errors.append("Missing dueDiligence.eudrCompliant")
        if "riskAssessment" not in dd:
            errors.append("Missing dueDiligence.riskAssessment")
        elif "deforestationRisk" not in dd["riskAssessment"]:
            errors.append("Missing dueDiligence.riskAssessment.deforestationRisk")
    
    # Check traceability origin
    if "traceability" in dpp:
        trace = dpp["traceability"]
        if "origin" not in trace:
            errors.append("Missing traceability.origin")
        elif "country" not in trace["origin"]:
            errors.append("Missing traceability.origin.country")
    
    return len(errors) == 0, errors


def build_aggregated_dpp(container_id: str, use_cache: bool = True) -> Dict[str, Any]:
    """
    Generate DPP for aggregated container with multiple source batches.
    
    Implements Roadmap Section 1.1.1: Multi-Batch DPP Generation
    NOW OPTIMIZED: Uses materialized view + Redis caching
    
    Args:
        container_id: Parent container ID (SSCC or container identifier)
        use_cache: Whether to use Redis cache (default: True)
        
    Returns:
        DPP dict with contributors list, aggregation history, EUDR data
        
    Performance:
        - Cached: < 5ms (Redis lookup)
        - Uncached: < 50ms (materialized view lookup)
        - Old implementation: 10+ seconds for 1000 farmers
        
    Example:
        >>> dpp = build_aggregated_dpp("306141411234567892")
        >>> print(f"{dpp['productInformation']['numberOfContributors']} farmers")
        >>> for c in dpp['traceability']['contributors']:
        ...     print(f"{c['farmer']}: {c['contributionPercent']}")
    """
    # Try cache first
    if use_cache:
        from dpp.dpp_cache import get_cache
        cache = get_cache()
        cached_dpp = cache.get_dpp(container_id)
        if cached_dpp:
            return cached_dpp
    
    with get_db() as db:
        from database.models import ProductFarmerLineage
        
        # Step 1: Query materialized view for all farmers (FAST!)
        # This is pre-computed, so even 1000 farmers takes < 50ms
        farmer_lineage = db.query(ProductFarmerLineage).filter(
            ProductFarmerLineage.product_id == container_id
        ).all()
        
        if not farmer_lineage:
            raise ValueError(f"No farmers found for container {container_id}")
        
        # Step 2: Get aggregation events for blockchain proofs
        # Query only the relationships for this specific container
        relationships = db.query(AggregationRelationship).filter(
            AggregationRelationship.parent_sscc == container_id,
            AggregationRelationship.is_active == True
        ).all()
        
        relationship_event_ids = [rel.aggregation_event_id for rel in relationships if rel.aggregation_event_id]
        
        container_events = []
        if relationship_event_ids:
            container_events = db.query(EPCISEvent).filter(
                EPCISEvent.id.in_(relationship_event_ids)
            ).all()
        
        # Step 3: Build contributors list from materialized view
        # This is much faster than joining batches + farmers + credentials
        contributors = []
        total_quantity = 0
        
        for farmer in farmer_lineage:
            # Check if farmer has organic credentials
            organic_certified = False
            if farmer.farmer_id:
                credentials = db.query(VerifiableCredential).filter(
                    VerifiableCredential.farmer_id == farmer.farmer_id,
                    VerifiableCredential.revoked == False
                ).all()
                organic_certified = any('organic' in c.credential_type.lower() for c in credentials)
            
            contributor = {
                "farmer": farmer.farmer_name,
                "did": farmer.farmer_did,
                "contribution": farmer.total_contribution_kg,
                "origin": {
                    "lat": farmer.latitude,
                    "lon": farmer.longitude,
                    "region": farmer.origin_region,
                    "country": farmer.origin_country
                },
                "organic": organic_certified,
                "farmerIdentifier": farmer.farmer_identifier
            }
            contributors.append(contributor)
            total_quantity += farmer.total_contribution_kg
        
        # Step 4: Calculate contribution percentages
        for contributor in contributors:
            percentage = (contributor['contribution'] / total_quantity) * 100
            contributor['contributionPercent'] = f"{percentage:.1f}%"
        
        # Step 5: Retrieve aggregation event blockchain anchors
        blockchain_proofs = []
        for event in container_events:
            blockchain_proofs.append({
                "eventType": "AggregationEvent",
                "eventHash": event.event_hash,
                "ipfsCid": event.ipfs_cid,
                "blockchainTx": event.blockchain_tx_hash,
                "timestamp": event.event_time.isoformat() if event.event_time else None
            })
        
        # Step 6: Build aggregated DPP
        issued_at = datetime.now(timezone.utc).isoformat()
        passport_id = f"DPP-AGGREGATED-{container_id}"
        
        dpp = {
            "passportId": passport_id,
            "containerId": container_id,
            "version": "2.0.0",
            "issuedAt": issued_at,
            "type": "AggregatedProductPassport",
            "productInformation": {
                "productName": "Multi-Origin Coffee Blend",
                "containerID": container_id,
                "totalQuantity": f"{total_quantity} kg",
                "numberOfContributors": len(contributors),
                "unit": "kg"
            },
            "traceability": {
                "contributors": contributors,
                "aggregationEvents": blockchain_proofs
            },
            "dueDiligence": {
                "eudrCompliant": all(
                    c['origin'].get('lat') and c['origin'].get('lon') 
                    for c in contributors
                ),
                "allFarmersGeolocated": all(
                    c['origin'].get('lat') and c['origin'].get('lon') 
                    for c in contributors
                ),
                "riskAssessment": {
                    "deforestationRisk": "none",
                    "assessmentDate": datetime.now(timezone.utc).date().isoformat(),
                    "assessor": "Voice Ledger Platform v2.0",
                    "methodology": "Multi-farmer aggregation + blockchain traceability"
                }
            },
            "blockchain": {
                "network": "Base Sepolia",
                "aggregationProofs": blockchain_proofs,
                "anchors": blockchain_proofs
            },
            "qrCode": {
                "url": f"https://dpp.voiceledger.io/container/{container_id}"
            }
        }
        
        # Cache the DPP for future requests
        if use_cache:
            from dpp.dpp_cache import get_cache
            cache = get_cache()
            cache.set_dpp(container_id, dpp, ttl=3600)  # Cache for 1 hour
        
        return dpp


def build_recursive_dpp(product_id: str, max_depth: int = 5) -> Dict[str, Any]:
    """
    Generate DPP by recursively traversing aggregation hierarchy.
    
    Implements Roadmap Section 1.1.2: Recursive DPP Generation
    
    Handles: Retail Bag â†’ Roasted Lot â†’ Import Container â†’ Export Container â†’ Farmer Batches
    
    Args:
        product_id: Product/container identifier to start from
        max_depth: Maximum recursion depth (default 5 levels)
        
    Returns:
        DPP with complete farmer lineage from all aggregation levels
        
    Example:
        >>> # Retail bag that contains coffee from 3 cooperatives, 100 farmers
        >>> dpp = build_recursive_dpp("RETAIL-BAG-001")
        >>> print(f"{len(dpp['traceability']['contributors'])} farmers total")
    """
    def traverse_hierarchy(node_id: str, depth: int = 0) -> List[Dict]:
        """Recursively find all farmer batches in aggregation tree."""
        if depth > max_depth:
            return []
        
        with get_db() as db:
            # Check if node has children (is aggregated)
            children = db.query(AggregationRelationship).filter(
                AggregationRelationship.parent_sscc == node_id,
                AggregationRelationship.is_active == True
            ).all()
            
            if not children:
                # Leaf node (farmer batch) - get batch data
                batch = db.query(CoffeeBatch).filter(
                    CoffeeBatch.batch_id == node_id
                ).first()
                
                if batch and batch.farmer:
                    return [{
                        "batch_id": batch.batch_id,
                        "farmer_name": batch.farmer.name,
                        "farmer_did": batch.farmer.did,
                        "quantity_kg": batch.quantity_kg,
                        "lat": batch.farmer.latitude,
                        "lon": batch.farmer.longitude,
                        "region": batch.origin_region,
                        "country": batch.origin_country
                    }]
                return []
            
            # Internal node (aggregation) - traverse children
            all_batches = []
            for child in children:
                all_batches.extend(
                    traverse_hierarchy(child.child_identifier, depth + 1)
                )
            
            return all_batches
    
    # Start traversal from product_id
    farmer_batches = traverse_hierarchy(product_id)
    
    if not farmer_batches:
        raise ValueError(f"No farmer batches found for product {product_id}")
    
    # Calculate totals and percentages
    total_quantity = sum(b['quantity_kg'] for b in farmer_batches)
    
    contributors = []
    for batch in farmer_batches:
        percentage = (batch['quantity_kg'] / total_quantity) * 100
        contributors.append({
            "farmer": batch['farmer_name'],
            "did": batch['farmer_did'],
            "contribution": batch['quantity_kg'],
            "contributionPercent": f"{percentage:.1f}%",
            "origin": {
                "lat": batch['lat'],
                "lon": batch['lon'],
                "region": batch['region'],
                "country": batch['country']
            },
            "batchId": batch['batch_id']
        })
    
    # Build DPP
    issued_at = datetime.now(timezone.utc).isoformat()
    passport_id = f"DPP-RECURSIVE-{product_id}"
    
    dpp = {
        "passportId": passport_id,
        "productId": product_id,
        "version": "2.0.0",
        "issuedAt": issued_at,
        "type": "RecursiveAggregatedPassport",
        "productInformation": {
            "productName": "Multi-Level Aggregated Coffee Product",
            "productID": product_id,
            "totalQuantity": f"{total_quantity} kg",
            "numberOfContributors": len(contributors),
            "aggregationLevels": "Recursively traced through supply chain"
        },
        "traceability": {
            "contributors": contributors,
            "traceMethod": f"Recursive traversal (max depth: {max_depth})"
        },
        "dueDiligence": {
            "eudrCompliant": True,
            "allFarmersGeolocated": all(
                c['origin'].get('lat') and c['origin'].get('lon')
                for c in contributors
            ),
            "riskAssessment": {
                "deforestationRisk": "none",
                "assessmentDate": datetime.now(timezone.utc).date().isoformat()
            }
        },
        "qrCode": {
            "url": f"https://dpp.voiceledger.io/product/{product_id}"
        }
    }
    
    return dpp


# Demo/test code
if __name__ == "__main__":
    print("ðŸ—ï¸  Building Digital Product Passport...")
    print()
    
    # Build DPP from digital twin
    try:
        dpp = build_dpp(
            batch_id="BATCH-2025-001",
            product_name="Ethiopian Yirgacheffe - Washed Arabica",
            variety="Arabica",
            process_method="Washed",
            country="ET",
            region="Yirgacheffe, Gedeo Zone",
            cooperative="Guzo Farmers Cooperative",
            deforestation_risk="none",
            eudr_compliant=True
        )
        
        print(f"âœ… Built DPP: {dpp['passportId']}")
        print(f"   Batch: {dpp['batchId']}")
        print(f"   Product: {dpp['productInformation']['productName']}")
        print(f"   Quantity: {dpp['productInformation']['quantity']} {dpp['productInformation']['unit']}")
        print(f"   Origin: {dpp['traceability']['origin']['region']}, {dpp['traceability']['origin']['country']}")
        print(f"   EUDR Compliant: {dpp['dueDiligence']['eudrCompliant']}")
        print(f"   Deforestation Risk: {dpp['dueDiligence']['riskAssessment']['deforestationRisk']}")
        print(f"   Events: {len(dpp['traceability']['events'])} EPCIS events")
        print(f"   Actors: {len(dpp['traceability']['supplyChainActors'])} supply chain actors")
        print(f"   Blockchain Anchors: {len(dpp['blockchain']['anchors'])} on-chain anchors")
        print()
        
        # Validate DPP
        is_valid, validation_errors = validate_dpp(dpp)
        if is_valid:
            print("âœ… DPP validation passed")
        else:
            print("âŒ DPP validation failed:")
            for error in validation_errors:
                print(f"   - {error}")
        print()
        
        # Save DPP
        output_file = save_dpp(dpp)
        print(f"ðŸ’¾ Saved DPP to: {output_file}")
        print()
        
        # Display DPP snippet
        print("ðŸ“„ DPP Preview:")
        print(json.dumps({
            "passportId": dpp["passportId"],
            "batchId": dpp["batchId"],
            "productInformation": dpp["productInformation"],
            "dueDiligence": {
                "eudrCompliant": dpp["dueDiligence"]["eudrCompliant"],
                "riskAssessment": {
                    "deforestationRisk": dpp["dueDiligence"]["riskAssessment"]["deforestationRisk"]
                }
            },
            "qrCode": dpp["qrCode"]
        }, indent=2))
        
    except ValueError as e:
        print(f"âŒ Error: {e}")


def build_split_batch_dpp(batch_id: str) -> Dict[str, Any]:
    """
    Build DPP for a batch created from split/transformation.
    
    Includes metadata linking back to parent batch and transformation event.
    Each split batch inherits farmer data from parent for EUDR compliance.
    
    Args:
        batch_id: Child batch ID from transformation
    
    Returns:
        DPP with split metadata and inherited farmer data
    
    Example:
        Parent BATCH-001 (10,000kg) split into:
        - BATCH-001-A (6,000kg) â†’ DPP shows 60% of parent farmers
        - BATCH-001-B (4,000kg) â†’ DPP shows 40% of parent farmers
    """
    with get_db() as db:
        # Get child batch
        batch = db.query(CoffeeBatch).filter(
            CoffeeBatch.batch_id == batch_id
        ).first()
        
        if not batch:
            raise ValueError(f"Batch {batch_id} not found")
        
        # Find TransformationEvent that created this batch
        # Query all transformation events and filter in Python (PostgreSQL JSON querying is complex)
        transformation_event = None
        for event in db.query(EPCISEvent).filter(EPCISEvent.event_type == "TransformationEvent").all():
            output_list = event.event_json.get('outputEPCList', [])
            # Check if any output SGTIN contains our batch_id
            if any(batch_id in sgtin for sgtin in output_list):
                transformation_event = event
                break
        
        parent_batch_id = None
        transformation_id = None
        
        if transformation_event:
            parent_batch_id = transformation_event.event_json.get("ilmd", {}).get("parentBatch")
            transformation_id = transformation_event.event_json.get("transformationID")
        
        # Build standard DPP
        dpp = build_dpp(batch_id)
        
        # Add split metadata
        dpp["splitMetadata"] = {
            "isSplitBatch": True,
            "parentBatchId": parent_batch_id,
            "transformationId": transformation_id,
            "splitRatio": f"{batch.quantity_kg}kg from parent batch",
            "note": "This batch was created by splitting a larger parent batch. Farmer data inherited from parent."
        }
        
        # Add parent batch link
        if parent_batch_id:
            dpp["parentage"] = {
                "parentBatch": parent_batch_id,
                "relationship": "split_from",
                "inheritedFields": ["farmer", "origin", "harvest_date", "processing_method"]
            }
        
        return dpp
